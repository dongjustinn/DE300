# -*- coding: utf-8 -*-
"""DE300_HW1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CSnwDIkrL9g8hLaRPzXjvrvtsezFg4W0
"""

import pandas as pd
import numpy as np

"""Question 1"""

df = pd.read_csv("/content/sample_data/T_F41SCHEDULE_B43.csv",
                 engine="python",        # More flexible Python-based parser
                 sep=",",               # Explicitly specify comma separator
                 on_bad_lines="skip",   # Skip lines with parsing errors
                 dtype=str,             # Force columns to be read as text       # Read in chunks to avoid partial type inference
                )

print("DataFrame loaded successfully!")
df.head()

df["CARRIER"].unique()

df["CAPACITY_IN_POUNDS"].unique()

df["CARRIER_NAME"].unique()

df["MANUFACTURE_YEAR"].unique()

df["NUMBER_OF_SEATS"].unique()

df["AIRLINE_ID"].unique()

cols = ["CARRIER",
        "CARRIER_NAME",
        "MANUFACTURE_YEAR",
        "NUMBER_OF_SEATS",
        "CAPACITY_IN_POUNDS",
        "AIRLINE_ID"]
df[cols].info()
df[cols].isna().sum()

df["CARRIER"].value_counts(dropna=False)
mask = df["CARRIER_NAME"].str.contains("North American Airlines", na=False)
df.loc[mask, ["CARRIER", "UNIQUE_CARRIER", "CARRIER_NAME"]]

"""When examining the columns for North American Airlines, it appears that the columns for Carrier and Unique Carrier are missing; however because we do know that they are linked to North American Airlines, that they are not actually missing. We can see that the "carrier" column is called NA, so we can impute that for the rest of the carrier column. Because the unique carrier column is NaN for all of North American Airlines entries, we can assume that we can also impute North American Airlines for this column as well."""

df["CARRIER"].value_counts(dropna=False)
mask = df["CARRIER"].str.contains("NA", na=False)
df.loc[mask, ["CARRIER", "UNIQUE_CARRIER", "CARRIER_NAME"]]

df[df["CARRIER"].isnull()]
df["CARRIER"].fillna("NA")

"""After further inspection, it appears the carrier column's NaN values only apply for North American Airlines. From the unique values of this column, the missing values only arise from a "nan" value, so we can be confident only North American Airlines have nan values in the carrier column. We can impute these with "NA."
"""

df[df["CARRIER_NAME"].isnull()]

"""It appears that when inspecting the carrier name column, the L4 and OH carriers are the only ones with a missing carrier name. Because there is no unique identification that would identify the carrier name, we cannot impute in this case.

For manufactured year column, we know that data that is greater than 2025, less than 1700 (too old, when I looked at the data, most of the reasonable data was in the 1900s/2000s). We also look for nan data that we saw when we swept for unique data points.
"""

df['MANUFACTURE_YEAR'] = pd.to_numeric(df['MANUFACTURE_YEAR'], errors='coerce')
invalid_years = df[
    (df['MANUFACTURE_YEAR'] > 2025) |
    (df['MANUFACTURE_YEAR'] < 1700) |
    (df['MANUFACTURE_YEAR'].isna())]
invalid_years
invalid_years.shape[0] / df.shape[0]  # % of problematic rows
# Drop them
df = df[(df['MANUFACTURE_YEAR'] >= 1700) & (df['MANUFACTURE_YEAR'] <= 2025)]

"""Because the invalid data for this constitutes about 0.04% of the dataset, we can call this insignificant and decide to drop this data.

An initial glance at the number of seats data lets us know that the unusual data points are the "0" and "None," as well as "NaN."
"""

df['NUMBER_OF_SEATS'] = pd.to_numeric(df['NUMBER_OF_SEATS'], errors='coerce')
invalid_seats = df[df['NUMBER_OF_SEATS'].isna()]
invalid_seats

"""After inspecting planes with 0 number of seats, there were about 900 entries. This made sense after seeing a majority of these being United Parcel Services, meaning that these were used to transport of luggage rather than people. However, there are Amerijet International planes that have NaN seats. However, we do have the knowledge that there might be other planes with the same aircraft type."""

df["AIRCRAFT_TYPE"] = pd.to_numeric(df["AIRCRAFT_TYPE"], errors="coerce")
df[df["AIRCRAFT_TYPE"] == 6262]

"""After further evaluation, it appears this aircraft type can be used in many different ways, especially in United Parcel Services. This cannot be reliably used to tell seat number. We can try to impute these data points with"""

from sklearn.impute import KNNImputer
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer, SimpleImputer
from sklearn.metrics import mean_squared_error

# Ensure numeric conversion
df['NUMBER_OF_SEATS'] = pd.to_numeric(df['NUMBER_OF_SEATS'], errors='coerce')
df['CAPACITY_IN_POUNDS'] = pd.to_numeric(df['CAPACITY_IN_POUNDS'], errors='coerce')
df['MANUFACTURE_YEAR'] = pd.to_numeric(df['MANUFACTURE_YEAR'], errors='coerce')

subset = df[['NUMBER_OF_SEATS', 'CAPACITY_IN_POUNDS', 'MANUFACTURE_YEAR']].dropna().sample(n=5000, random_state=1)

np.random.seed(0)
mask = np.random.rand(len(subset)) < 0.2
test_data = subset.copy()
test_data.loc[mask, 'NUMBER_OF_SEATS'] = np.nan

true_values = subset.loc[mask, 'NUMBER_OF_SEATS']

mean_data = test_data.copy()
median_data = test_data.copy()
knn_data = test_data.copy()
pmm_data = test_data.copy()

# Mean Imputation
mean_imputer = SimpleImputer(strategy='mean')
mean_data['NUMBER_OF_SEATS'] = mean_imputer.fit_transform(mean_data[['NUMBER_OF_SEATS']])

# Median Imputation
median_imputer = SimpleImputer(strategy='median')
median_data['NUMBER_OF_SEATS'] = median_imputer.fit_transform(median_data[['NUMBER_OF_SEATS']])

# KNN Imputation
knn_imputer = KNNImputer(n_neighbors=5)
knn_data_imputed = knn_imputer.fit_transform(knn_data)
knn_data['NUMBER_OF_SEATS'] = knn_data_imputed[:, 0]

# PMM Imputation
pmm_imputer = IterativeImputer(random_state=0, sample_posterior=True)
pmm_data_imputed = pmm_imputer.fit_transform(pmm_data)
pmm_data['NUMBER_OF_SEATS'] = pmm_data_imputed[:, 0]

rmse_results = {
    'Mean Imputation': mean_squared_error(true_values, mean_data.loc[mask, 'NUMBER_OF_SEATS']),
    'Median Imputation': mean_squared_error(true_values, median_data.loc[mask, 'NUMBER_OF_SEATS']),
    'KNN Imputation': mean_squared_error(true_values, knn_data.loc[mask, 'NUMBER_OF_SEATS']),
    'PMM Imputation': mean_squared_error(true_values, pmm_data.loc[mask, 'NUMBER_OF_SEATS']),}

print(rmse_results)

"""KNN Imputation provides the lowest RMSE, so we will use KNN Imputation for this."""

missing_mask = df['NUMBER_OF_SEATS'].isna()
impute_cols = ['NUMBER_OF_SEATS', 'CAPACITY_IN_POUNDS', 'MANUFACTURE_YEAR']
impute_df = df[impute_cols]
rows_to_impute = impute_df.copy()

# Apply KNN imputation
knn_imputer = KNNImputer(n_neighbors=5)
imputed_array = knn_imputer.fit_transform(impute_df)

# Replace only the 'NUMBER_OF_SEATS' column in original DataFrame with imputed values
df.loc[missing_mask, 'NUMBER_OF_SEATS'] = imputed_array[missing_mask, 0]

"""Now let's move onto capacity in pounds."""

invalid_capacity = df[
    (df['CAPACITY_IN_POUNDS'] < 0) |
    (df['CAPACITY_IN_POUNDS'].isna())]
invalid_capacity

"""There is a substantial amount of data here, about 100 rows that have missing data."""

capacity_full = df[['CAPACITY_IN_POUNDS', 'NUMBER_OF_SEATS', 'MANUFACTURE_YEAR']].dropna().sample(n=5000, random_state=42)

np.random.seed(1)
mask = np.random.rand(len(capacity_full)) < 0.2
test_data = capacity_full.copy()
test_data.loc[mask, 'CAPACITY_IN_POUNDS'] = np.nan

true_values_capacity = capacity_full.loc[mask, 'CAPACITY_IN_POUNDS']

mean_data = test_data.copy()
median_data = test_data.copy()
knn_data = test_data.copy()
pmm_data = test_data.copy()

# Mean Imputation
mean_imputer = SimpleImputer(strategy='mean')
mean_data['CAPACITY_IN_POUNDS'] = mean_imputer.fit_transform(mean_data[['CAPACITY_IN_POUNDS']])

# Median Imputation
median_imputer = SimpleImputer(strategy='median')
median_data['CAPACITY_IN_POUNDS'] = median_imputer.fit_transform(median_data[['CAPACITY_IN_POUNDS']])

# KNN Imputation
knn_imputer = KNNImputer(n_neighbors=5)
knn_data_imputed = knn_imputer.fit_transform(knn_data)
knn_data['CAPACITY_IN_POUNDS'] = knn_data_imputed[:, 0]

# PMM-like Imputation using IterativeImputer
pmm_imputer = IterativeImputer(random_state=0, sample_posterior=True)
pmm_data_imputed = pmm_imputer.fit_transform(pmm_data)
pmm_data['CAPACITY_IN_POUNDS'] = pmm_data_imputed[:, 0]

# Step 5: Compute RMSE for each method
rmse_capacity = {
    'Mean Imputation': mean_squared_error(true_values_capacity, mean_data.loc[mask, 'CAPACITY_IN_POUNDS']),
    'Median Imputation': mean_squared_error(true_values_capacity, median_data.loc[mask, 'CAPACITY_IN_POUNDS']),
    'KNN Imputation': mean_squared_error(true_values_capacity, knn_data.loc[mask, 'CAPACITY_IN_POUNDS']),
    'PMM Imputation': mean_squared_error(true_values_capacity, pmm_data.loc[mask, 'CAPACITY_IN_POUNDS']),}

print(rmse_capacity)

"""KNN has the lowest RMSE value, so we will use KNN Imputation."""

missing_mask = df['CAPACITY_IN_POUNDS'].isna()

impute_features = ['CAPACITY_IN_POUNDS', 'NUMBER_OF_SEATS', 'MANUFACTURE_YEAR']
impute_data = df[impute_features]

knn_imputer = KNNImputer(n_neighbors=5)
imputed_array = knn_imputer.fit_transform(impute_data)

df.loc[missing_mask, 'CAPACITY_IN_POUNDS'] = imputed_array[missing_mask, 0]

"""Let's move onto Airline ID."""

df[df['AIRLINE_ID'].isna()]

df[df['CARRIER'] == 'L4'] # We can see the airline ID is 21217 for L4.
df[df['CARRIER'] == 'OH'] # We can see the airline ID is 20417 or 20397 for OH, pretty even split between the two

oh_airline_ids = df[df['CARRIER'] == 'OH']['AIRLINE_ID'].dropna()

oh_id_counts = oh_airline_ids.value_counts()

print(oh_id_counts)

"""We can impute the 21217 for L4. Because for OH, there are two, we check to see which is the majority, and 20397 has more than 20417, so we use the former.




"""

df.loc[(df['CARRIER'] == 'L4') & (df['AIRLINE_ID'].isna()), 'AIRLINE_ID'] = 21217
df.loc[(df['CARRIER'] == 'OH') & (df['AIRLINE_ID'].isna()), 'AIRLINE_ID'] = 20397

"""**Question 2**"""

df["MANUFACTURER"].value_counts()

df["MANUFACTURER"].unique()

"""We are going to categorize each name we see into a standardization map. We will take the unique entries that we see line up and put them to one name. (e.g. All the Boeing variations will be linked to BOEING). For those with two names separated by a slash, we will check to see if either are known manufacturers, and if not, we will just use the full name as a manufacturer."""

import pandas as pd
import numpy as np

standardization_map = {
    'BOEING': ['BOEING', 'BOEINGCOMPANY', 'BOEINGCO', 'THEBOEINGCOMPANY', 'THEBOEINGCO',
               'TheBoeingCompany', 'Boeing', 'BoeingCo', 'TheBOEINGCO', 'BOEINGCOMPANY ', 'BoeingCo.'],
    'AIRBUS': ['AIRBUS', 'AIRBUSINDUSTRIES', 'AirbusIndustrie', 'Airbus', 'AirbusCompany',
               'AirBlue/Airbus'],
    'MCDONNELL-DOUGLAS': ['MCDONNELL-DOUGLAS', 'MCDONNELLDOUGLAS', 'McDonnellDouglas',
                          'McDonnell-Douglas', 'MCDONNELLDOUG', 'MDDouglas', 'McDonnelDouglas',
                          'McDonaldDouglas', 'DOUGLAS', 'DOUGLASAIRCRAFT', 'Douglas','MCDONNELL','MCDONNEL',
                          'MCDONNELLDOUGLASMD11-F'],
    'BOMBARDIER': ['BOMBARDIER', 'Bombardier', 'BombardierAerospace'],
    'CESSNA': ['CESSNA', 'Cessna', 'CSSNACITATIONX'],
    'LOCKHEED': ['LOCKHEED', 'Lockheed'],
    'GULFSTREAM': ['GULFSTREAM', 'GULFSTREAMAEROSPACE', 'GULFSTREAMAEROSPACECORP', 'Gulfstream'],
    'DASSAULT': ['DASSAULT', 'DASSAULT SUD', 'Dassault', 'DASSAULT/SUD', 'Dassault-Falcon-2000EXEASy',
                 'DASSULT SUD'],
    'PIPER': ['PIPER', 'Piper'],
    'SAAB': ['SAAB', 'SAAB AIRCRAFT', 'Saab', 'SAABFairchild', 'SAABScania', 'SAAB-Fairchild'],
    'FOKKER': ['FOKKER', 'FOKKER72', 'FOKKER70', 'FOKKER71', 'FOKKERAIRCRAFTUSA'],
    'DEHAVILLAND': ['DEHAVILLAND', 'DeHavilland', 'deHavilland'],
    'RAYTHEON': ['RAYTHEON', 'Raetheon'],
    'BEECHCRAFT': ['BEECHCRAFT', 'BEECHHAWKER400XP'],
    'LEARJET': ['LEAR', 'Learjet', 'LearjetInc'],
    'IAI': ['IAI', 'ISRAELAIRCRAFTINDUSTRIES', 'IAILTD'],
    'CHALLENGER': ['CHALLENGER', 'Challenger', 'Challenger300']}

known_manufacturers = [
    'BOEING', 'AIRBUS', 'MCDONNELL-DOUGLAS', 'BOMBARDIER', 'EMBRAER', 'CESSNA', 'LOCKHEED', 'GULFSTREAM',
    'DASSAULT', 'PIPER', 'SAAB', 'FOKKER', 'DEHAVILLAND', 'RAYTHEON', 'BEECHCRAFT', 'LEARJET', 'IAI',
    'DORNIER', 'ATR', 'FAIRCHILD', 'CONVAIR', 'BAE', 'HAWKER', 'CHALLENGER', 'PILATUS', 'SIKORSKY',
    'AGUSTAWESTLAND', 'PIPISTREL', 'AEROSPATIALE', 'CFM', 'GE', 'ROLLS-ROYCE', 'CASA']

reverse_map = {variant.upper(): standard for standard, variants in standardization_map.items() for variant in variants}

def clean_manufacturer(name):
    if pd.isna(name):
        return np.nan
    name = name.strip().upper()

    if name in reverse_map:
        return reverse_map[name]

    if '/' in name:
        parts = name.split('/')
        parts = [part.strip().upper() for part in parts]

        for part in parts:
            if part in known_manufacturers:
                return part

        return name

    return name

df['MANUFACTURER_CLEAN'] = df['MANUFACTURER'].apply(clean_manufacturer)
print(df['MANUFACTURER_CLEAN'].value_counts(dropna=False))

"""Now we will investigate model."""

models = df['MODEL'].dropna().unique().tolist()
for model in models:
    print(model)

import numpy as np

def standardize_model(model):
    if pd.isna(model):
        return np.nan
    model = model.strip().upper()

    if '737' in model:
        return 'B737'
    elif '747' in model:
        return 'B747'
    elif '757' in model:
        return 'B757'
    elif '767' in model:
        return 'B767'
    elif '777' in model:
        return 'B777'
    elif '787' in model:
        return 'B787'

    elif 'A318' in model:
        return 'A318'
    elif 'A319' in model:
        return 'A319'
    elif 'A320' in model:
        return 'A320'
    elif 'A321' in model:
        return 'A321'
    elif 'A330' in model:
        return 'A330'
    elif 'A350' in model:
        return 'A350'

    elif 'E170' in model or 'ERJ170' in model:
        return 'E170'
    elif 'E175' in model or 'ERJ175' in model:
        return 'E175'
    elif 'E190' in model or 'ERJ190' in model:
        return 'E190'
    elif 'E195' in model or 'ERJ195' in model:
        return 'E195'

    elif 'CRJ200' in model or 'CRJ-2' in model:
        return 'CRJ200'
    elif 'CRJ700' in model or 'RJ-700' in model:
        return 'CRJ700'
    elif 'CRJ900' in model:
        return 'CRJ900'

    elif 'CESSNA' in model or 'CITATION' in model:
        return 'CESSNA'

    elif 'GULFSTREAM' in model or 'GULF' in model:
        return 'GULFSTREAM'

    elif 'CHALLENGER' in model:
        return 'CHALLENGER'

    return model

df['MODEL'] = df['MODEL'].apply(standardize_model)

df['MODEL'].value_counts()

df['AIRCRAFT_STATUS'].unique()
df['AIRCRAFT_STATUS'].value_counts()

df['AIRCRAFT_STATUS'] = df['AIRCRAFT_STATUS'].str.upper().str.strip()
df['AIRCRAFT_STATUS'].value_counts()

df['OPERATING_STATUS'].value_counts()

"""Because for operating status, there are two Ys, we can merge them. We can also drop the one value that is just a blank."""

df['OPERATING_STATUS'] = df['OPERATING_STATUS'].str.upper().str.strip()

df = df[df['OPERATING_STATUS'].notna() & (df['OPERATING_STATUS'] != '')]

# Step 3 (Optional): Check value counts again
df['OPERATING_STATUS'].value_counts()

"""**Question 3**"""

df_cleaned = df.dropna()

print(f"Remaining rows after dropping missing values: {len(df_cleaned)}")
percentage_remaining = len(df_cleaned)/len(df)
print(f"Percentage of rows remaining: {percentage_remaining}")

"""**Question 4**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import boxcox

cols = ['NUMBER_OF_SEATS', 'CAPACITY_IN_POUNDS']

df_transformed = df.copy()

for col in cols:
    valid = df_transformed[col] > 0
    transformed, _ = boxcox(df_transformed.loc[valid, col])
    df_transformed.loc[valid, f'{col}_BOXCOX'] = transformed

fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))

for i, col in enumerate(cols):
    df_transformed[col].hist(ax=axes[i, 0], bins=40)
    axes[i, 0].set_title(f'{col} - Before Box-Cox')
    df_transformed[f'{col}_BOXCOX'].dropna().hist(ax=axes[i, 1], bins=40)
    axes[i, 1].set_title(f'{col} - After Box-Cox')

plt.tight_layout()
plt.show()

"""**Question 5**"""

import pandas as pd
import matplotlib.pyplot as plt

df['SIZE'] = pd.qcut(
    df['NUMBER_OF_SEATS'],
    q=4,
    labels=['SMALL','MEDIUM','LARGE','XLARGE'])

df['OPERATING_STATUS'] = df['OPERATING_STATUS'].str.upper().str.strip()
df['AIRCRAFT_STATUS'] = df['AIRCRAFT_STATUS'].str.upper().str.strip()

ops_props = (
    df.groupby('SIZE')['OPERATING_STATUS']
    .value_counts(normalize=True)
    .unstack(fill_value=0))

fig, ax = plt.subplots()
ops_props.plot(kind='bar', ax=ax)
ax.set_title('Operating Status Proportions by Size')
ax.set_xlabel('Size Quartile')
ax.set_ylabel('Proportion')
ax.legend(title='Operating?')
plt.tight_layout()
plt.show()

status_props = (
    df.groupby('SIZE')['AIRCRAFT_STATUS']
    .value_counts(normalize=True)
    .unstack(fill_value=0))

fig, ax = plt.subplots()
status_props.plot(kind='bar', ax=ax)
ax.set_title('Aircraft Status Proportions by Size')
ax.set_xlabel('Size Quartile')
ax.set_ylabel('Proportion')
ax.legend(title='Status')
plt.tight_layout()
plt.show()